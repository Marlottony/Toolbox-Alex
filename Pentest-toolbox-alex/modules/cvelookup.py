import requests
import re
import json
from bs4 import BeautifulSoup

def underline_text(text):
    return f"\033[4m{text}\033[0m"

def CVELookUpNVD(cve_id):
    url = f"https://services.nvd.nist.gov/rest/json/cve/1.0/{cve_id}"
    try:
        response = requests.get(url)
        response.raise_for_status()
    except requests.RequestException as e:
        return f"Error connecting to the NVD API: {e}"

    try:
        cve_data = response.json()
    except json.JSONDecodeError as e:
        return f"Error parsing JSON data: {e}"

    cve_items = cve_data.get('result', {}).get('CVE_Items', [])
    if not cve_items:
        return "No information found for this CVE."

    cve_info = cve_items[0]
    description = cve_info.get('cve', {}).get('description', {}).get('description_data', [{}])[0].get('value', 'No description available')
    impact = cve_info.get('impact', {})
    base_metric_v3 = impact.get('baseMetricV3', {})
    base_score = base_metric_v3.get('cvssV3', {}).get('baseScore', 'Not available')
    severity = base_metric_v3.get('cvssV3', {}).get('baseSeverity', 'Not available')

    details = f"CVE ID: {cve_id}\nDescription: {description}\nBase Score (CVSS v3): {base_score}\nSeverity: {severity}\n"
    return details

def CVELookUp(id, htmlRender=False):
    URL = f"https://www.cvedetails.com/cve/{id}/?q={id}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept-Language': 'en-US,en;q=0.9',
    }
    
    try:
        cveQuery = requests.get(URL, headers=headers)
        cveQuery.raise_for_status()
    except requests.RequestException as e:
        return f"Error connecting to the CVE Details site: {e}"
    
    if "Unknown CVE ID" in cveQuery.text:
        return "This CVE is not referenced or does not exist."

    spacing = "<br>" if htmlRender else "\n"
    html = cveQuery.content
    soup = BeautifulSoup(html, "html.parser")
    displayInfos = ""

    # Find the CVE details summary
    cveDescriptionTag = soup.find('div', {'id': 'cvedetailssummary'})
    if cveDescriptionTag:
        description = cveDescriptionTag.text.strip()
        displayInfos += f"{spacing}\033[32m{underline_text('Description:')} {description}\033[0m{spacing}"

    # Find the CVSS score
    cvss_score_box = soup.find('div', {'class': 'cvssbox'})
    if cvss_score_box:
        cvss_score = cvss_score_box.text.strip()
        displayInfos += f"{spacing}{underline_text('CVSS Score:')} {cvss_score}{spacing}"

    # Find the publication and update dates
    published_date_tag = soup.find(text=re.compile('Published')).parent
    updated_date_tag = soup.find(text=re.compile('Updated')).parent

    published_date = published_date_tag.next_sibling.strip() if published_date_tag else "Not available"
    updated_date = updated_date_tag.next_sibling.strip() if updated_date_tag else "Not available"

    displayInfos += f"{spacing}\033[34m{underline_text('Published Date:')} {published_date}\033[0m{spacing}"
    displayInfos += f"{spacing}\033[34m{underline_text('Updated Date:')} {updated_date}\033[0m{spacing}"

    # Find the source
    source_tag = soup.find('a', href=re.compile(r'^/vulnerability-list/assigner-'))
    source = source_tag.text.strip() if source_tag else "Not available"
    displayInfos += f"{spacing}\033[33m{underline_text('Source:')} {source}\033[0m{spacing}"

    # Find the vulnerability category
    category_tag = soup.find('span', {'class': 'ssc-vuln-cat'})
    category = category_tag.text.strip() if category_tag else "Not available"
    displayInfos += f"{spacing}{underline_text('Vulnerability Category:')} {category}{spacing}"

    # Find CWE IDs
    cwe_tags = soup.find_all('a', href=re.compile(r'^/cwe-details/'))
    if cwe_tags:
        cwes = ", ".join([tag.text.strip() for tag in cwe_tags])
        displayInfos += f"{spacing}{underline_text('CWE IDs:')} {cwes}{spacing}"

    # Find references
    reference_tags = soup.find_all('a', href=re.compile(r'^https?://'))
    references = [tag['href'] for tag in reference_tags if 'noopener' in tag.get('rel', [])]
    if references:
        displayInfos += f"{spacing}\033[38;5;214m{underline_text('References:')}\033[0m{spacing}" + spacing.join(references)

    # Find affected products
    affected_products = []
    product_tags = soup.find_all('div', class_='list-group-item')
    for tag in product_tags:
        product_info = tag.find_all('a')
        if product_info:
            vendor = product_info[0].text.strip()
            product = product_info[1].text.strip()
            version = tag.find('span', class_='text-secondary').text.strip() if tag.find('span', class_='text-secondary') else "N/A"
            affected_products.append(f"{vendor} {product} {version}")

    if affected_products:
        displayInfos += f"{spacing}{underline_text('Affected Products:')}{spacing}" + spacing.join(affected_products)

    if not htmlRender:
        displayInfos += f"{spacing}==================================={spacing}"
        displayInfos += f"Information on {id}{spacing}"
        displayInfos += f"==================================={spacing}"

    return displayInfos

def extract_and_detail_cves_from_url(url):
    """Extract and return details for all unique CVE identifiers found on a web page."""
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
    except requests.RequestException as e:
        return f"Error connecting to the site: {e}"

    content_type = response.headers.get('Content-Type')
    if 'application/json' in content_type:
        try:
            cve_data = response.json()
            cve_ids = [item['cve']['CVE_data_meta']['ID'] for item in cve_data['result']['CVE_Items']]
        except json.JSONDecodeError as e:
            return f"Error parsing JSON data: {e}"
    else:
        soup = BeautifulSoup(response.text, 'html.parser')
        text = soup.get_text()
        cve_pattern = re.compile(r'CVE-\d{4}-\d{4,9}')
        cve_ids = set(re.findall(cve_pattern, text))

    if not cve_ids:
        return "No CVEs found on this page."

    cves_details = {}
    for cve_id in cve_ids:
        cves_details[cve_id] = CVELookUp(cve_id)
    
    return cves_details

def displayMenu():
    print("\n=== Main Menu ===")
    print("e. Extract CVEs from a URL")
    print("q. Quit")

def input_with_retry(prompt, expected_type):
    while True:
        try:
            return expected_type(input(prompt))
        except ValueError:
            print(f"Error: Please enter a value of type {expected_type.__name__}.")

if __name__ == "__main__":
    while True:
        displayMenu()
        option = input_with_retry(">>> Choose an option\n>>> ", str).strip().lower()
        
        if option == 'e':
            url = input(">>> Enter the URL to extract CVEs: ")
            cves_details = extract_and_detail_cves_from_url(url)
            if isinstance(cves_details, str):
                print(cves_details)  # Print an error message or "No CVEs found"
            else:
                print("\nDetails of CVEs found at the specified URL:\n")
                for cve_id, details in cves_details.items():
                    print(f"{cve_id} : {details}")
        
        elif option == 'q':
            print("Goodbye!")
            break
        else:
            print("Unrecognized option, please try again.")
